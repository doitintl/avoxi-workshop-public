{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "copyright"
   },
   "outputs": [],
   "source": [
    "# Copyright 2022 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# Custom model batch prediction with feature filtering \n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/custom_batch_prediction_feature_filter.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Google Colaboratory logo\"><br> Open in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fvertex-ai-samples%2Fmain%2Fnotebooks%2Fofficial%2Fprediction%2Fcustom_batch_prediction_feature_filter.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://cloud.google.com/ml-engine/images/colab-enterprise-logo-32px.png\" alt=\"Google Cloud Colab Enterprise logo\"><br> Open in Colab Enterprise\n",
    "    </a>\n",
    "  </td>    \n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/vertex-ai-samples/main/notebooks/official/prediction/custom_batch_prediction_feature_filter.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\"><br> Open in Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/official/prediction/custom_batch_prediction_feature_filter.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\"><br> View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mEXYaDoTjmpR"
   },
   "source": [
    "## Overview\n",
    "\n",
    "\n",
    "This tutorial demonstrates how to use the Vertex AI SDK for Python to train a custom tabular classification model and perform batch prediction with feature filtering. This means that you can run batch prediction on a list of selected features or exclude a list of features from prediction.\n",
    "\n",
    "Learn more about [Vertex AI Batch Prediction](https://cloud.google.com/vertex-ai/docs/tabular-data/classification-regression/get-batch-predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "objective:custom,training,online_prediction"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this notebook, you learn how to create a custom-trained model from a Python script in a Docker container using the Vertex AI SDK for Python, and then run a batch prediction job by including or excluding a list of features. \n",
    "\n",
    "This tutorial uses the following Google Cloud ML services and resources:\n",
    "\n",
    "- BigQuery\n",
    "- Cloud Storage\n",
    "- Vertex AI managed Datasets\n",
    "- Vertex AI Training\n",
    "- Vertex AI BatchPrediction\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Create a Vertex AI custom `TrainingPipeline` for training a model.\n",
    "- Train a TensorFlow model.\n",
    "- Send batch prediction job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dataset:custom,cifar10,icn"
   },
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset used for this tutorial is the penguins dataset from [BigQuery public datasets](https://cloud.google.com/bigquery/public-data). This dataset has the following fields: `culmen_length_mm`, `culmen_depth_mm`, `flipper_length_mm`, `body_mass_g` from the dataset to predict the penguins species (`species`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "costs"
   },
   "source": [
    "### Costs\n",
    "\n",
    "This tutorial uses billable components of Google Cloud:\n",
    "\n",
    "* Vertex AI\n",
    "* Cloud Storage\n",
    "* BigQuery\n",
    "\n",
    "Learn about [Vertex AI\n",
    "pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage\n",
    "pricing](https://cloud.google.com/storage/pricing), [BigQuery pricing](https://cloud.google.com/bigquery/pricing) and use the [Pricing\n",
    "Calculator](https://cloud.google.com/products/calculator/)\n",
    "to generate a cost estimate based on your projected usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b1ffd5ab768"
   },
   "source": [
    "## Get Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "install_aip"
   },
   "source": [
    "### Install Vertex AI SDK for Python and other required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fd00fa70a2a"
   },
   "outputs": [],
   "source": [
    "# Install the packages\n",
    "! pip3 install --upgrade --quiet google-cloud-aiplatform \\\n",
    "                                 google-cloud-storage \\\n",
    "                                 google-cloud-bigquery \\\n",
    "                                 pyarrow \\\n",
    "                                 db-dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ff555b32bab8"
   },
   "source": [
    "### Restart runtime (Colab only)\n",
    "\n",
    "To use the newly installed packages, you must restart the runtime on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f09b4dff629a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54c5ef8a8f43"
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ The kernel is going to restart. Wait until it's finished before continuing to the next step. ⚠️</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f82e28c631cc"
   },
   "source": [
    "### Authenticate your notebook environment (Colab only)\n",
    "\n",
    "Authenticate your environment on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46604f70e831"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6a870411c189"
   },
   "source": [
    "### Set Google Cloud project information and initialize Vertex AI SDK for Python\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com). Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "60af003fe0ed",
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"gurkomal-playground\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bucket:custom"
   },
   "source": [
    "### Create a Cloud Storage bucket\n",
    "\n",
    "Create a storage bucket to store intermediate artifacts such as datasets.\n",
    "\n",
    "When you submit a training job using the Cloud SDK, you upload a Python package\n",
    "containing your training code to a Cloud Storage bucket. Vertex AI runs\n",
    "the code from this package. In this tutorial, Vertex AI also saves the\n",
    "trained model that results from your job in the same bucket. Using this model artifact, you can then\n",
    "create Vertex AI Model resource and use for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bucket",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET_URI = f\"gs://bq-test-gurkomal-{PROJECT_ID}-unique\"  # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Oz8J0vmSlugt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://bq-test-gurkomal-gurkomal-playground-unique/...\n"
     ]
    }
   ],
   "source": [
    "! gsutil mb -l {LOCATION} -p {PROJECT_ID} {BUCKET_URI}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_aip"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cNEiwLd0lugu",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from google.cloud import aiplatform, bigquery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init_aip:mbsdk,all"
   },
   "source": [
    "### Initialize Vertex AI SDK for Python\n",
    "\n",
    "Initialize the Vertex SDK for Python for your project and corresponding bucket.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "856023874e71",
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=LOCATION, staging_bucket=BUCKET_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>island</th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>body_mass_g</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.351846</td>\n",
       "      <td>0.627215</td>\n",
       "      <td>-1.210563</td>\n",
       "      <td>-0.909144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.766694</td>\n",
       "      <td>0.982683</td>\n",
       "      <td>-1.210563</td>\n",
       "      <td>0.550092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.565548</td>\n",
       "      <td>0.881121</td>\n",
       "      <td>-1.210563</td>\n",
       "      <td>-0.381335</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.458467</td>\n",
       "      <td>0.373309</td>\n",
       "      <td>-0.639777</td>\n",
       "      <td>-0.878096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.223844</td>\n",
       "      <td>-0.185283</td>\n",
       "      <td>-0.639777</td>\n",
       "      <td>-1.499048</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   island  culmen_length_mm  culmen_depth_mm  flipper_length_mm  body_mass_g  \\\n",
       "0       0         -1.351846         0.627215          -1.210563    -0.909144   \n",
       "1       0         -0.766694         0.982683          -1.210563     0.550092   \n",
       "2       0         -0.565548         0.881121          -1.210563    -0.381335   \n",
       "3       0          0.458467         0.373309          -0.639777    -0.878096   \n",
       "4       0         -1.223844        -0.185283          -0.639777    -1.499048   \n",
       "\n",
       "   sex  \n",
       "0    0  \n",
       "1    1  \n",
       "2    1  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV file into a DataFrame\n",
    "df = pd.read_csv('output.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame to verify\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_file_name='my_output.jsonl'\n",
    "df.head(10).to_json(data_file_name, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://my_output.jsonl [Content-Type=application/octet-stream]...\n",
      "/ [1 files][  1.3 KiB/  1.3 KiB]                                                \n",
      "Operation completed over 1 objects/1.3 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp \"{data_file_name}\" \"{BUCKET_URI}/{data_file_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"island\":0,\"culmen_length_mm\":-1.3518456,\"culmen_depth_mm\":0.6272151,\"flipper_length_mm\":-1.2105628,\"body_mass_g\":-0.909144,\"sex\":0}\n",
      "{\"island\":0,\"culmen_length_mm\":-0.7666939,\"culmen_depth_mm\":0.98268336,\"flipper_length_mm\":-1.2105628,\"body_mass_g\":0.5500921,\"sex\":1}\n",
      "{\"island\":0,\"culmen_length_mm\":-0.56554765,\"culmen_depth_mm\":0.88112074,\"flipper_length_mm\":-1.2105628,\"body_mass_g\":-0.3813352,\"sex\":1}\n",
      "{\"island\":0,\"culmen_length_mm\":0.45846736,\"culmen_depth_mm\":0.3733094,\"flipper_length_mm\":-0.63977706,\"body_mass_g\":-0.8780964,\"sex\":0}\n",
      "{\"island\":0,\"culmen_length_mm\":-1.2238436,\"culmen_depth_mm\":-0.18528321,\"flipper_length_mm\":-0.63977706,\"body_mass_g\":-1.499048,\"sex\":0}\n",
      "{\"island\":0,\"culmen_length_mm\":-0.14497007,\"culmen_depth_mm\":0.6779964,\"flipper_length_mm\":-0.63977706,\"body_mass_g\":-0.13295458,\"sex\":1}\n",
      "{\"island\":0,\"culmen_length_mm\":0.53161156,\"culmen_depth_mm\":-0.28684488,\"flipper_length_mm\":-0.63977706,\"body_mass_g\":-1.8716189,\"sex\":0}\n",
      "{\"island\":0,\"culmen_length_mm\":1.1899068,\"culmen_depth_mm\":0.6272151,\"flipper_length_mm\":-0.06899122,\"body_mass_g\":-1.0022867,\"sex\":0}\n",
      "{\"island\":0,\"culmen_length_mm\":1.0070469,\"culmen_depth_mm\":0.93190205,\"flipper_length_mm\":-0.06899122,\"body_mass_g\":-0.50552547,\"sex\":1}\n",
      "{\"island\":0,\"culmen_length_mm\":-0.6935497,\"culmen_depth_mm\":1.4904946,\"flipper_length_mm\":-0.06899122,\"body_mass_g\":-0.28819245,\"sex\":1}\n"
     ]
    }
   ],
   "source": [
    "# Inspect if file was successfully uploaded to GCS\n",
    "!gsutil cat \"{BUCKET_URI}/{data_file_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "send_prediction_request:image"
   },
   "source": [
    "### Send the BatchPredictionJob request using REST API\n",
    "\n",
    "Now that you have test data, you can use it to send a batch prediction request using REST API. To do that you need to create a `JSON` request with the following information:\n",
    "\n",
    "- `BATCH_JOB_NAME`: Display name for the batch prediction job.\n",
    "- `MODEL_URI`: The URI for the Model resource to use for making predictions.\n",
    "- `INPUT_FORMAT`: The format of your input data: bigquery, jsonl, csv, tf-record, tf-record-gzip, or file-list.\n",
    "- `INPUT_URI`: Cloud Storage URI of your input data. May contain wildcards.\n",
    "- `OUTPUT_URI`: Cloud Storage URI of a directory where you want Vertex AI to save output.\n",
    "- `MACHINE_TYPE`: The machine resources to be used for this batch prediction job.\n",
    "\n",
    "In this example, we create two versions of the same JSON request: one with `excludedFields` and the other with `includeFields` to show how to include or exclude certain features. Note that these two requests do the same job in this example!\n",
    "\n",
    "Learn more about [request a batch prediction](https://cloud.google.com/vertex-ai/docs/predictions/get-predictions#api_1)<br>\n",
    "Learn more about [instanceconfig](https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/projects.locations.batchPredictionJobs#instanceconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "ofwR2WTcjmpY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_JOB_NAME = \"keras-batch\"\n",
    "#MODEL_URI = model.resource_name\n",
    "MODEL_URI=\"projects/506365831141/locations/us-central1/models/2574608731018887168\"\n",
    "INPUT_FORMAT = \"jsonl\"\n",
    "INSTANCE_TYPE=\"array\"\n",
    "INPUT_URI = f\"{BUCKET_URI}/{data_file_name}\"\n",
    "OUTPUT_FORMAT = \"jsonl\"\n",
    "OUTPUT_URI = f\"{BUCKET_URI}/output\"\n",
    "MACHINE_TYPE = \"n1-standard-2\"\n",
    "\n",
    "# Create a list of columns to be included\n",
    "INCLUDED_FIELDS = list(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJdI9L5fjmpY"
   },
   "source": [
    "### Create JSON body requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "e95Rk92fjmpZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "request_with_included_fields = {\n",
    "    \"displayName\": f\"{BATCH_JOB_NAME}-included_fields\",\n",
    "    \"model\": MODEL_URI,\n",
    "    \"inputConfig\": {\n",
    "        \"instancesFormat\": INPUT_FORMAT,\n",
    "        \"gcsSource\": {\"uris\": INPUT_URI},\n",
    "    },\n",
    "    \"outputConfig\": {\n",
    "        \"predictionsFormat\": OUTPUT_FORMAT,\n",
    "        \"gcsDestination\": {\"outputUriPrefix\": OUTPUT_URI},\n",
    "    },\n",
    "    \"dedicatedResources\": {\n",
    "        \"machineSpec\": {\n",
    "            \"machineType\": MACHINE_TYPE,\n",
    "        }\n",
    "    },\n",
    "    \"instanceConfig\": {\n",
    "        \"includedFields\": INCLUDED_FIELDS,\n",
    "        \"instanceType\": INSTANCE_TYPE,\n",
    "    },\n",
    "}\n",
    "\n",
    "with open(\"request_with_included_fields.json\", \"w\") as outfile:\n",
    "    json.dump(request_with_included_fields, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPIYouoVjmpZ"
   },
   "source": [
    "### Send the requests\n",
    "\n",
    "To send the requests, specify the API version you want to use. In this case you use `v1beta1` to be able to use `instanceConfig`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QPK1jQRejmpZ"
   },
   "source": [
    "#### Include fields\n",
    "\n",
    "Here, we send the request with `includedFields`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "1vXC7fNBjmpZ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"projects/506365831141/locations/us-central1/batchPredictionJobs/8688026319281192960\",\n",
      "  \"displayName\": \"keras-batch-included_fields\",\n",
      "  \"model\": \"projects/506365831141/locations/us-central1/models/2574608731018887168\",\n",
      "  \"inputConfig\": {\n",
      "    \"instancesFormat\": \"jsonl\",\n",
      "    \"gcsSource\": {\n",
      "      \"uris\": [\n",
      "        \"gs://bq-test-gurkomal-gurkomal-playground-unique/my_output.jsonl\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"outputConfig\": {\n",
      "    \"predictionsFormat\": \"jsonl\",\n",
      "    \"gcsDestination\": {\n",
      "      \"outputUriPrefix\": \"gs://bq-test-gurkomal-gurkomal-playground-unique/output\"\n",
      "    }\n",
      "  },\n",
      "  \"dedicatedResources\": {\n",
      "    \"machineSpec\": {\n",
      "      \"machineType\": \"n1-standard-2\"\n",
      "    }\n",
      "  },\n",
      "  \"manualBatchTuningParameters\": {},\n",
      "  \"state\": \"JOB_STATE_PENDING\",\n",
      "  \"createTime\": \"2024-08-31T04:25:35.285706Z\",\n",
      "  \"updateTime\": \"2024-08-31T04:25:35.285706Z\",\n",
      "  \"instanceConfig\": {\n",
      "    \"instanceType\": \"array\",\n",
      "    \"includedFields\": [\n",
      "      \"island\",\n",
      "      \"culmen_length_mm\",\n",
      "      \"culmen_depth_mm\",\n",
      "      \"flipper_length_mm\",\n",
      "      \"body_mass_g\",\n",
      "      \"sex\"\n",
      "    ]\n",
      "  },\n",
      "  \"modelVersionId\": \"1\",\n",
      "  \"modelMonitoringStatus\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl \\\n",
    "  -X POST \\\n",
    "  -H \"Authorization: Bearer $(gcloud auth print-access-token)\" \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -d @request_with_included_fields.json \\\n",
    "  https://{LOCATION}-aiplatform.googleapis.com/v1beta1/projects/{PROJECT_ID}/locations/{LOCATION}/batchPredictionJobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:custom"
   },
   "source": [
    "### Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NNmebHf7lug0"
   },
   "outputs": [],
   "source": [
    "# Warning: Setting this to true deletes everything in your bucket\n",
    "delete_bucket = True\n",
    "\n",
    "if delete_bucket:\n",
    "    ! gsutil rm -r $BUCKET_URI"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "custom_batch_prediction_feature_filter.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
