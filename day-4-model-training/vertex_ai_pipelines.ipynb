{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f19a975d-14d6-47e8-a6fb-8f0aa964b219",
   "metadata": {},
   "source": [
    "### Vertex AI Pipelines Demo\n",
    "* Submits Vertex AI Training job\n",
    "* Training job submits Dataproc Serverless batch job for preprocessing\n",
    "* Results stored in GCS bucket\n",
    "* Preprocessing.py only splits the data into 2 categories (anomaly vs not anomaly) based on certain column values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3ac6b1-01af-4332-a05e-704e297096da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install google-cloud-pipeline-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72cf355-2d8a-44b4-a310-2e707daad61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pyspark --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd96b2f3-6b9e-437a-8730-9ee9ad8a9562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PROJECT_ID='gurkomal-playground'\n",
    "REGION='us-central1'\n",
    "BUCKET_URI='gs://avoxi_workshop_bucket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7990286f-7da0-4cf1-9fdb-0d99f4d848f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_7328/344022202.py:2: DeprecationWarning: The module `kfp.v2` is deprecated and will be removed in a futureversion. Please import directly from the `kfp` namespace, instead of `kfp.v2`.\n",
      "  from kfp.v2 import dsl\n"
     ]
    }
   ],
   "source": [
    "import google.cloud.aiplatform as aiplatform\n",
    "from kfp.v2 import dsl\n",
    "from kfp.v2.dsl import component, Output, Dataset, Model\n",
    "from kfp.v2 import compiler\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1007507a-779e-41e7-8864-9a23b430c1ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, staging_bucket=f'{BUCKET_URI}/staging')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "105cd3af-3fca-4b0f-8db1-0cf82a48c994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from kfp import local\n",
    "\n",
    "local.init(runner=local.DockerRunner(), raise_on_error=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37363950-aa10-4588-a7c8-02c4d9954c51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/kfp/dsl/component_decorator.py:119: FutureWarning: The default base_image used by the @dsl.component decorator will switch from 'python:3.8' to 'python:3.9' on Oct 1, 2024. To ensure your existing components work with versions of the KFP SDK released after that date, you should provide an explicit base_image argument and ensure your component works as intended on Python 3.9.\n",
      "  return component_factory.create_component_from_func(\n"
     ]
    }
   ],
   "source": [
    "@component(packages_to_install=[\"google-cloud-bigquery==3.25.0\"])\n",
    "def create_bigquery_tables(anomaly_data_path: str, no_anomaly_data_path: str, anomaly_table_name: str, no_anomaly_table_name: str):\n",
    "    from google.cloud import bigquery\n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define the external connection for anomaly data\n",
    "    external_config_anomaly = bigquery.ExternalConfig('CSV')\n",
    "    external_config_anomaly.source_uris = [f\"{anomaly_data_path}*.csv\"]\n",
    "    external_config_anomaly.autodetect = True\n",
    "\n",
    "    # Define the external connection for non-anomaly data\n",
    "    external_config_no_anomaly = bigquery.ExternalConfig('CSV')\n",
    "    external_config_no_anomaly.source_uris = [f\"{no_anomaly_data_path}*.csv\"]\n",
    "    external_config_no_anomaly.autodetect = True\n",
    "\n",
    "    # Create or replace the anomaly table\n",
    "    table_anomaly = bigquery.Table(anomaly_table_name)\n",
    "    table_anomaly.external_data_configuration = external_config_anomaly\n",
    "    client.create_table(table_anomaly, exists_ok=True)\n",
    "\n",
    "    # Create or replace the non-anomaly table\n",
    "    table_no_anomaly = bigquery.Table(no_anomaly_table_name)\n",
    "    table_no_anomaly.external_data_configuration = external_config_no_anomaly\n",
    "    client.create_table(table_no_anomaly, exists_ok=True)\n",
    "\n",
    "    print(f\"BigQuery tables created successfully: {anomaly_table_name}, {no_anomaly_table_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1783ffb-588d-4672-b440-b77b08e82b79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_config(config_gcs_path : str) -> dict:\n",
    "    import json\n",
    "    from google.cloud import storage\n",
    "    from datetime import datetime\n",
    "    import yaml\n",
    "    # Initialize GCS client\n",
    "    storage_client = storage.Client()\n",
    "    \n",
    "    # Extract the bucket name and blob (file) name from the config GCS path\n",
    "    bucket_name, blob_name = config_gcs_path.replace(\"gs://\", \"\").split(\"/\", 1)\n",
    "    \n",
    "    # Download the YAML file from GCS\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    config_data = blob.download_as_text()\n",
    "    config_data = yaml.safe_load(config_data)\n",
    "    TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "    BATCH_ID = \"avoxi-workshop-\" + TIMESTAMP\n",
    "    config_data['batch_id'] = BATCH_ID\n",
    "    return config_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3be13967-1f48-4360-b848-f15cfc88c4dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config=get_config(\"gs://avoxi_workshop_bucket/data_pipeline/configuration.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23e44837-c1ec-4d32-9faa-baff3dfcd3af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15:38:41.086 - INFO - Executing task \u001b[96m'create-bigquery-tables'\u001b[0m\n",
      "15:38:41.087 - INFO - Streamed logs:\n",
      "\n",
      "    Found image 'python:3.8'\n",
      "\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "    kfp 2.8.0 requires click<9,>=8.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires docstring-parser<1,>=0.7.3, which is not installed.\n",
      "    kfp 2.8.0 requires google-cloud-storage<3,>=2.2.1, which is not installed.\n",
      "    kfp 2.8.0 requires kfp-pipeline-spec==0.3.0, which is not installed.\n",
      "    kfp 2.8.0 requires kfp-server-api<2.1.0,>=2.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires kubernetes<27,>=8.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires PyYAML<7,>=5.3, which is not installed.\n",
      "    kfp 2.8.0 requires requests-toolbelt<1,>=0.8.0, which is not installed.\n",
      "    kfp 2.8.0 requires tabulate<1,>=0.8.6, which is not installed.\n",
      "    kfp 2.8.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.28.0 which is incompatible.\n",
      "    kfp 2.8.0 requires urllib3<2.0.0, but you have urllib3 2.2.2 which is incompatible.\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    \n",
      "    [notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "    [notice] To update, run: pip install --upgrade pip\n",
      "    [KFP Executor 2024-09-11 15:39:12,354 INFO]: Looking for component `create_bigquery_tables` in --component_module_path `/tmp/tmp.L1YVUIWfVp/ephemeral_component.py`\n",
      "    [KFP Executor 2024-09-11 15:39:12,355 INFO]: Loading KFP component \"create_bigquery_tables\" from /tmp/tmp.L1YVUIWfVp/ephemeral_component.py (directory \"/tmp/tmp.L1YVUIWfVp\" and module name \"ephemeral_component\")\n",
      "    [KFP Executor 2024-09-11 15:39:12,358 INFO]: Got executor_input:\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"parameterValues\": {\n",
      "                \"no_anomaly_table_name\": \"gurkomal-playground.avoxi_workshop.no_anomaly_table\",\n",
      "                \"anomaly_data_path\": \"gs://avoxi_workshop_bucket/data/output/v1/anomaly_normalized/\",\n",
      "                \"anomaly_table_name\": \"gurkomal-playground.avoxi_workshop.anomaly_table\",\n",
      "                \"no_anomaly_data_path\": \"gs://avoxi_workshop_bucket/data/output/v1/no_anomaly_normalized/\"\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"outputFile\": \"/home/jupyter/Avoxi/DoiT/avoxi-workshop/day-4-model-training/local_outputs/create-bigquery-tables-2024-09-11-15-38-41-085955/create-bigquery-tables/executor_output.json\"\n",
      "        }\n",
      "    }\n",
      "    BigQuery tables created successfully: gurkomal-playground.avoxi_workshop.anomaly_table, gurkomal-playground.avoxi_workshop.no_anomaly_table\n",
      "    [KFP Executor 2024-09-11 15:39:13,845 INFO]: Wrote executor output file to /home/jupyter/Avoxi/DoiT/avoxi-workshop/day-4-model-training/local_outputs/create-bigquery-tables-2024-09-11-15-38-41-085955/create-bigquery-tables/executor_output.json.\n",
      "    /usr/local/lib/python3.8/runpy.py:111: FutureWarning: KFP will drop support for Python 3.8 on Oct 1, 2024. To use new versions of the KFP SDK after that date, you will need to upgrade to Python >= 3.9. See https://devguide.python.org/versions/ for more details.\n",
      "      __import__(pkg_name)\n",
      "15:39:14.506 - INFO - Task \u001b[96m'create-bigquery-tables'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
      "15:39:14.510 - INFO - Task \u001b[96m'create-bigquery-tables'\u001b[0m has no outputs\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<kfp.dsl.pipeline_task.PipelineTask at 0x7fcdc0c27b80>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create BigQuery tables\n",
    "create_bigquery_tables(\n",
    "    anomaly_data_path=config['dataproc_args']['anomaly_normalized_output'],\n",
    "    no_anomaly_data_path=config['dataproc_args']['no_anomaly_normalized_output'],\n",
    "    anomaly_table_name=config['anomaly_table_name'],\n",
    "    no_anomaly_table_name=config['no_anomaly_table_name']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d8e21d6e-2576-41d5-858b-7f37ac6f9bc3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/506365831141/locations/us-central1/endpoints/2692098145516519424/operations/4810817641620963328\n",
      "Endpoint created. Resource name: projects/506365831141/locations/us-central1/endpoints/2692098145516519424\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/506365831141/locations/us-central1/endpoints/2692098145516519424')\n"
     ]
    }
   ],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    project=config['project_id'],\n",
    "    location=config['location'],\n",
    "    display_name=config['endpoint_name'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b510306f-894c-494f-901d-cfe595e24b69",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-bigquery==3.25.0\"])\n",
    "def train_model(config: dict):\n",
    "    from google.cloud import bigquery\n",
    "    \n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define the SQL query to create the model and save it in the model registry\n",
    "    create_model_query = config['create_model_query'].format(**config)\n",
    "    \n",
    "    # Execute the query\n",
    "    query_job = client.query(create_model_query)\n",
    "    query_job.result()  # Wait for the job to complete\n",
    "\n",
    "    print(f\"Model {config['model_name']} created and saved in model registry at {config['model_registry_path']} successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eaca8f2e-4439-4993-aceb-92af70a9e2d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:16:47.857 - INFO - Executing task \u001b[96m'train-model'\u001b[0m\n",
      "21:16:47.860 - INFO - Streamed logs:\n",
      "\n",
      "    Found image 'python:3.8'\n",
      "\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "    kfp 2.8.0 requires click<9,>=8.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires docstring-parser<1,>=0.7.3, which is not installed.\n",
      "    kfp 2.8.0 requires google-cloud-storage<3,>=2.2.1, which is not installed.\n",
      "    kfp 2.8.0 requires kfp-pipeline-spec==0.3.0, which is not installed.\n",
      "    kfp 2.8.0 requires kfp-server-api<2.1.0,>=2.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires kubernetes<27,>=8.0.0, which is not installed.\n",
      "    kfp 2.8.0 requires PyYAML<7,>=5.3, which is not installed.\n",
      "    kfp 2.8.0 requires requests-toolbelt<1,>=0.8.0, which is not installed.\n",
      "    kfp 2.8.0 requires tabulate<1,>=0.8.6, which is not installed.\n",
      "    kfp 2.8.0 requires protobuf<5,>=4.21.1, but you have protobuf 5.28.0 which is incompatible.\n",
      "    kfp 2.8.0 requires urllib3<2.0.0, but you have urllib3 2.2.2 which is incompatible.\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    \n",
      "    [notice] A new release of pip is available: 23.0.1 -> 24.2\n",
      "    [notice] To update, run: pip install --upgrade pip\n",
      "    [KFP Executor 2024-09-10 21:17:08,310 INFO]: Looking for component `train_model` in --component_module_path `/tmp/tmp.2EgMi1UAL9/ephemeral_component.py`\n",
      "    [KFP Executor 2024-09-10 21:17:08,310 INFO]: Loading KFP component \"train_model\" from /tmp/tmp.2EgMi1UAL9/ephemeral_component.py (directory \"/tmp/tmp.2EgMi1UAL9\" and module name \"ephemeral_component\")\n",
      "    [KFP Executor 2024-09-10 21:17:08,312 INFO]: Got executor_input:\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"parameterValues\": {\n",
      "                \"config\": {\n",
      "                    \"model_id\": \"autoencoder_v2\",\n",
      "                    \"model_registry_name\": \"bq_autoencoder_v1\",\n",
      "                    \"no_anomaly_table_name\": \"gurkomal-playground.avoxi_workshop.no_anomaly_table\",\n",
      "                    \"main_python_file\": \"gs://avoxi_workshop_bucket/data_pipeline/preprocessing_v2.py\",\n",
      "                    \"dataset_id\": \"avoxi_workshop\",\n",
      "                    \"project_id\": \"gurkomal-playground\",\n",
      "                    \"dedicated_resources_min_replica_count\": 1.0,\n",
      "                    \"bq_location\": \"US\",\n",
      "                    \"dedicated_resources_machine_type\": \"n1-standard-2\",\n",
      "                    \"anomaly_table_name\": \"gurkomal-playground.avoxi_workshop.anomaly_table\",\n",
      "                    \"testing\": true,\n",
      "                    \"endpoint_name\": \"test\",\n",
      "                    \"bucket\": \"gs://avoxi_workshop_bucket\",\n",
      "                    \"runtime_config_properties\": {\n",
      "                        \"spark.dynamicAllocation.enabled\": \"true\",\n",
      "                        \"spark.executor.instances\": \"2\",\n",
      "                        \"spark.executor.memoryOverhead\": \"3g\",\n",
      "                        \"spark.driver.memory\": \"3g\",\n",
      "                        \"spark.driver.memoryOverhead\": \"3g\",\n",
      "                        \"spark.dynamicAllocation.maxExecutors\": \"2\",\n",
      "                        \"spark.executor.memory\": \"3g\"\n",
      "                    },\n",
      "                    \"create_model_query\": \"CREATE OR REPLACE MODEL `{model_name}` OPTIONS(\\n    model_type='AUTOENCODER',\\n    batch_size=32,\\n    hidden_units=[8, 4, 2, 4, 8],\\n    activation_fn='RELU',\\n    optimizer='ADAM',\\n    learn_rate=0.01,\\n    max_iterations=10,\\n    early_stop=TRUE,\\n    model_registry='{model_registry_path}'\\n) AS (\\n    SELECT\\n        packet_loss,\\n        duration,\\n        jitter,\\n        mean_opinion_score\\n    FROM (\\n        SELECT * FROM `{anomaly_table_name}`\\n        UNION ALL\\n        SELECT * FROM `{no_anomaly_table_name}`\\n    )\\n);\",\n",
      "                    \"enable_caching\": true,\n",
      "                    \"batch_id\": \"avoxi-workshop-20240910210333\",\n",
      "                    \"dataproc_args\": {\n",
      "                        \"input\": \"gs://avoxi_workshop_bucket/large_table/\",\n",
      "                        \"no_anomaly_output\": \"gs://avoxi_workshop_bucket/large_table_cleaned/v7/no_anom/\",\n",
      "                        \"no_anomaly_normalized_output\": \"gs://avoxi_workshop_bucket/large_table_cleaned/v7/no_anomaly_normalized_output/\",\n",
      "                        \"anomaly_normalized_output\": \"gs://avoxi_workshop_bucket/large_table_cleaned/v7/anomaly_normalized_output/\",\n",
      "                        \"output\": \"gs://avoxi_workshop_bucket/large_table_cleaned/v7/output/\",\n",
      "                        \"anomaly_output\": \"gs://avoxi_workshop_bucket/large_table_cleaned/v7/anom/\"\n",
      "                    },\n",
      "                    \"model_name\": \"gurkomal-playground.avoxi_workshop.autoencoder_v4\",\n",
      "                    \"image_uri\": \"gcr.io/gurkomal-playground/avoxi-workshop-image:1.0.3\",\n",
      "                    \"dedicated_resources_max_replica_count\": 1.0,\n",
      "                    \"deployed_model_display_name\": \"autoencoderv1\",\n",
      "                    \"reference_metric_name\": \"mean_squared_error\",\n",
      "                    \"location\": \"us-central1\",\n",
      "                    \"model_thresholds\": {\n",
      "                        \"mean_squared_error\": 2.09\n",
      "                    },\n",
      "                    \"model_registry_path\": \"VERTEX_AI\"\n",
      "                }\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"outputFile\": \"/home/jupyter/Avoxi/DoiT/avoxi-workshop/day-4-model-training/local_outputs/train-model-2024-09-10-21-16-47-855513/train-model/executor_output.json\"\n",
      "        }\n",
      "    }\n",
      "    /usr/local/lib/python3.8/runpy.py:111: FutureWarning: KFP will drop support for Python 3.8 on Oct 1, 2024. To use new versions of the KFP SDK after that date, you will need to upgrade to Python >= 3.9. See https://devguide.python.org/versions/ for more details.\n",
      "      __import__(pkg_name)\n",
      "    Traceback (most recent call last):\n",
      "      File \"/usr/local/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "        return _run_code(code, main_globals, None,\n",
      "      File \"/usr/local/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "        exec(code, run_globals)\n",
      "      File \"/usr/local/lib/python3.8/site-packages/kfp/dsl/executor_main.py\", line 109, in <module>\n",
      "        executor_main()\n",
      "      File \"/usr/local/lib/python3.8/site-packages/kfp/dsl/executor_main.py\", line 101, in executor_main\n",
      "        output_file = executor.execute()\n",
      "      File \"/usr/local/lib/python3.8/site-packages/kfp/dsl/executor.py\", line 361, in execute\n",
      "        result = self.func(**func_kwargs)\n",
      "      File \"/tmp/tmp.2EgMi1UAL9/ephemeral_component.py\", line 18, in train_model\n",
      "        query_job.result()  # Wait for the job to complete\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py\", line 1676, in result\n",
      "        while not is_job_done():\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
      "        return retry_target(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
      "        _retry_error_helper(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
      "        raise final_exc from source_exc\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
      "        result = target()\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py\", line 1645, in is_job_done\n",
      "        self._reload_query_results(retry=retry, **reload_query_results_kwargs)\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py\", line 1443, in _reload_query_results\n",
      "        self._query_results = self._client._get_query_results(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py\", line 2024, in _get_query_results\n",
      "        resource = self._call_api(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/bigquery/client.py\", line 833, in _call_api\n",
      "        return call()\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 293, in retry_wrapped_func\n",
      "        return retry_target(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 153, in retry_target\n",
      "        _retry_error_helper(\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_base.py\", line 212, in _retry_error_helper\n",
      "        raise final_exc from source_exc\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py\", line 144, in retry_target\n",
      "        result = target()\n",
      "      File \"/usr/local/lib/python3.8/site-packages/google/cloud/_http/__init__.py\", line 494, in api_request\n",
      "        raise exceptions.from_http_response(response)\n",
      "    google.api_core.exceptions.BadRequest: 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/gurkomal-playground/queries/19926994-e95d-4e50-abd8-1473192790e5?maxResults=0&location=US&prettyPrint=false: Input data doesn't contain any rows.\n",
      "    \n",
      "    Location: US\n",
      "    Job ID: 19926994-e95d-4e50-abd8-1473192790e5\n",
      "    \n",
      "21:17:12.653 - ERROR - Task \u001b[96m'train-model'\u001b[0m finished with status \u001b[91mFAILURE\u001b[0m\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<kfp.dsl.pipeline_task.PipelineTask at 0x7f9da264cca0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "train_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d2be4402-e531-411a-986f-856168535997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-bigquery==3.25.0\"])\n",
    "def evaluate_model(model_name: str, dataset_name: str, metric: str) -> float:\n",
    "    from google.cloud import bigquery\n",
    "\n",
    "    # Initialize BigQuery client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Define the SQL query to evaluate the model\n",
    "    evaluate_model_query = f\"\"\"\n",
    "    SELECT\n",
    "        {metric}\n",
    "    FROM\n",
    "        ML.EVALUATE(MODEL `{model_name}`, (\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                `{dataset_name}`\n",
    "        ))\n",
    "    \"\"\"\n",
    "\n",
    "    # Execute the query\n",
    "    query_job = client.query(evaluate_model_query)\n",
    "    results = query_job.result()\n",
    "\n",
    "    # Extract MSE from the results\n",
    "    mse = None\n",
    "    for row in results:\n",
    "        print(f\"{metric} score: {row[metric]}\")\n",
    "        mse = row[metric]\n",
    "        break\n",
    "\n",
    "    if mse is None:\n",
    "        raise ValueError(\"Mean Squared Error (MSE) not found in evaluation results.\")\n",
    "\n",
    "    print(f\"Model {model_name} evaluated with MSE: {mse}\")\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2a51042-344c-4685-8f94-96b40bf8acd4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:15:22.914 - INFO - Executing task \u001b[96m'evaluate-model'\u001b[0m\n",
      "23:15:22.915 - INFO - Streamed logs:\n",
      "\n",
      "    Found image 'python:3.7'\n",
      "\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "    kfp 2.7.0 requires click<9,>=8.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires docstring-parser<1,>=0.7.3, which is not installed.\n",
      "    kfp 2.7.0 requires google-cloud-storage<3,>=2.2.1, which is not installed.\n",
      "    kfp 2.7.0 requires kfp-pipeline-spec==0.3.0, which is not installed.\n",
      "    kfp 2.7.0 requires kfp-server-api<2.1.0,>=2.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires kubernetes<27,>=8.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires PyYAML<7,>=5.3, which is not installed.\n",
      "    kfp 2.7.0 requires requests-toolbelt<1,>=0.8.0, which is not installed.\n",
      "    kfp 2.7.0 requires tabulate<1,>=0.8.6, which is not installed.\n",
      "    kfp 2.7.0 requires urllib3<2.0.0, but you have urllib3 2.0.7 which is incompatible.\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    \n",
      "    [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "    [notice] To update, run: pip install --upgrade pip\n",
      "    [KFP Executor 2024-08-15 23:15:40,557 INFO]: Looking for component `evaluate_model` in --component_module_path `/tmp/tmp.86ElVP9Gxi/ephemeral_component.py`\n",
      "    [KFP Executor 2024-08-15 23:15:40,557 INFO]: Loading KFP component \"evaluate_model\" from /tmp/tmp.86ElVP9Gxi/ephemeral_component.py (directory \"/tmp/tmp.86ElVP9Gxi\" and module name \"ephemeral_component\")\n",
      "    [KFP Executor 2024-08-15 23:15:40,559 INFO]: Got executor_input:\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"parameterValues\": {\n",
      "                \"dataset_name\": \"gurkomal-playground.avoxi_workshop.anomaly_table\",\n",
      "                \"metric\": \"mean_squared_error\",\n",
      "                \"model_name\": \"avoxi_workshop.autoencoder_v1\"\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"parameters\": {\n",
      "                \"Output\": {\n",
      "                    \"outputFile\": \"/home/jupyter/local_outputs/evaluate-model-2024-08-15-23-15-22-913493/evaluate-model/Output\"\n",
      "                }\n",
      "            },\n",
      "            \"outputFile\": \"/home/jupyter/local_outputs/evaluate-model-2024-08-15-23-15-22-913493/evaluate-model/executor_output.json\"\n",
      "        }\n",
      "    }\n",
      "    mean_squared_error score: 11.438526625708217\n",
      "    Model avoxi_workshop.autoencoder_v1 evaluated with MSE: 11.438526625708217\n",
      "    [KFP Executor 2024-08-15 23:15:43,329 INFO]: Wrote executor output file to /home/jupyter/local_outputs/evaluate-model-2024-08-15-23-15-22-913493/evaluate-model/executor_output.json.\n",
      "    /usr/local/lib/python3.7/runpy.py:109: FutureWarning: Python 3.7 has reached end-of-life. KFP will drop support for Python 3.7 on April 23, 2024. To use new versions of the KFP SDK after that date, you will need to upgrade to Python >= 3.8. See https://devguide.python.org/versions/ for more details.\n",
      "      __import__(pkg_name)\n",
      "23:15:43.972 - INFO - Task \u001b[96m'evaluate-model'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
      "23:15:43.974 - INFO - Task \u001b[96m'evaluate-model'\u001b[0m outputs:\n",
      "    Output: 11.438526625708217\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# # Evaluate model\n",
    "mse = evaluate_model(model_name=config['model_name'], dataset_name=config['eval_dataset'], metric=config['eval_metric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7e3daa22-5099-4c7c-bad8-96e4f387ebf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component\n",
    "def compare_metrics(blessed_mse: float, challenger_mse: float, default_mse_threshold: float) -> bool:\n",
    "    # Define the default MSE threshold for deployment\n",
    "    default_mse_threshold = 0.1  # Adjust this threshold as needed\n",
    "\n",
    "    # Compare MSE values\n",
    "    if challenger_mse < blessed_mse and challenger_mse < default_mse_threshold:\n",
    "        print(f\"Challenger model MSE ({challenger_mse}) is better than blessed model MSE ({blessed_mse}). Deploying challenger model.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(f\"Challenger model MSE ({challenger_mse}) is not better than blessed model MSE ({blessed_mse}). Keeping blessed model.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "889a7c3f-8902-4c10-9b9f-a9d0d535ba5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:18:44.618 - INFO - Executing task \u001b[96m'compare-metrics'\u001b[0m\n",
      "23:18:44.621 - INFO - Streamed logs:\n",
      "\n",
      "    Found image 'python:3.7'\n",
      "\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    [KFP Executor 2024-08-15 23:18:51,119 INFO]: Looking for component `compare_metrics` in --component_module_path `/tmp/tmp.LmVsaeNFvp/ephemeral_component.py`\n",
      "    [KFP Executor 2024-08-15 23:18:51,119 INFO]: Loading KFP component \"compare_metrics\" from /tmp/tmp.LmVsaeNFvp/ephemeral_component.py (directory \"/tmp/tmp.LmVsaeNFvp\" and module name \"ephemeral_component\")\n",
      "    [KFP Executor 2024-08-15 23:18:51,121 INFO]: Got executor_input:\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"parameterValues\": {\n",
      "                \"default_mse_threshold\": 0.1,\n",
      "                \"challenger_mse\": 11.438526625708217,\n",
      "                \"blessed_mse\": 0.15\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"parameters\": {\n",
      "                \"Output\": {\n",
      "                    \"outputFile\": \"/home/jupyter/local_outputs/compare-metrics-2024-08-15-23-18-44-618003/compare-metrics/Output\"\n",
      "                }\n",
      "            },\n",
      "            \"outputFile\": \"/home/jupyter/local_outputs/compare-metrics-2024-08-15-23-18-44-618003/compare-metrics/executor_output.json\"\n",
      "        }\n",
      "    }\n",
      "    /usr/local/lib/python3.7/runpy.py:109: FutureWarning: Python 3.7 has reached end-of-life. KFP will drop support for Python 3.7 on April 23, 2024. To use new versions of the KFP SDK after that date, you will need to upgrade to Python >= 3.8. See https://devguide.python.org/versions/ for more details.\n",
      "      __import__(pkg_name)\n",
      "    Challenger model MSE (11.438526625708217) is not better than blessed model MSE (0.15). Keeping blessed model.\n",
      "    [KFP Executor 2024-08-15 23:18:51,121 INFO]: Wrote executor output file to /home/jupyter/local_outputs/compare-metrics-2024-08-15-23-18-44-618003/compare-metrics/executor_output.json.\n",
      "23:18:51.420 - INFO - Task \u001b[96m'compare-metrics'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
      "23:18:51.422 - INFO - Task \u001b[96m'compare-metrics'\u001b[0m outputs:\n",
      "    Output: False\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# # Compare metrics\n",
    "should_deploy = compare_metrics(blessed_mse=config['blessed_model_mse'], challenger_mse=mse.output, default_mse_threshold=config['default_mse_threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a5351a83-01c3-4b9e-842d-bc892f78cbac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "config_file=\"config.yaml\"\n",
    "with open(config_file, 'r') as file:\n",
    "        config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0ddefdc8-36d8-40c2-ba8b-529b6916d958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@component(packages_to_install=[\"google-cloud-aiplatform\"])\n",
    "def deploy_model(project_id:str, location: str, model_name: str, endpoint_name: str, should_deploy: bool, machine_type: str):\n",
    "    from google.cloud import aiplatform\n",
    "    \n",
    "    if should_deploy:\n",
    "        # Initialize Vertex AI SDK\n",
    "        aiplatform.init(project=project_id, location=location)\n",
    "\n",
    "        # Get the model\n",
    "        model = aiplatform.Model(model_name)\n",
    "\n",
    "        # Get the endpoint\n",
    "        endpoint = aiplatform.Endpoint(endpoint_name)\n",
    "\n",
    "        # Deploy the model to the endpoint\n",
    "        model.deploy(endpoint=endpoint, machine_type=machine_type)\n",
    "\n",
    "        print(f\"Model {model_name} deployed to endpoint {endpoint_name} successfully.\")\n",
    "    else:\n",
    "        print(\"Model deployment skipped as per comparison result.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cee02f17-7c48-4e06-8a8f-1112dce38fde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23:23:26.859 - INFO - Executing task \u001b[96m'deploy-model'\u001b[0m\n",
      "23:23:26.864 - INFO - Streamed logs:\n",
      "\n",
      "    Found image 'python:3.7'\n",
      "\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "    kfp 2.7.0 requires click<9,>=8.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires docstring-parser<1,>=0.7.3, which is not installed.\n",
      "    kfp 2.7.0 requires kfp-pipeline-spec==0.3.0, which is not installed.\n",
      "    kfp 2.7.0 requires kfp-server-api<2.1.0,>=2.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires kubernetes<27,>=8.0.0, which is not installed.\n",
      "    kfp 2.7.0 requires PyYAML<7,>=5.3, which is not installed.\n",
      "    kfp 2.7.0 requires requests-toolbelt<1,>=0.8.0, which is not installed.\n",
      "    kfp 2.7.0 requires tabulate<1,>=0.8.6, which is not installed.\n",
      "    kfp 2.7.0 requires urllib3<2.0.0, but you have urllib3 2.0.7 which is incompatible.\n",
      "    WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "    \n",
      "    [notice] A new release of pip is available: 23.0.1 -> 24.0\n",
      "    [notice] To update, run: pip install --upgrade pip\n",
      "    [KFP Executor 2024-08-15 23:23:49,141 INFO]: Looking for component `deploy_model` in --component_module_path `/tmp/tmp.mtY1KxIBQV/ephemeral_component.py`\n",
      "    [KFP Executor 2024-08-15 23:23:49,141 INFO]: Loading KFP component \"deploy_model\" from /tmp/tmp.mtY1KxIBQV/ephemeral_component.py (directory \"/tmp/tmp.mtY1KxIBQV\" and module name \"ephemeral_component\")\n",
      "    [KFP Executor 2024-08-15 23:23:49,142 INFO]: Got executor_input:\n",
      "    {\n",
      "        \"inputs\": {\n",
      "            \"parameterValues\": {\n",
      "                \"model_name\": \"avoxi_workshop.autoencoder_v1\",\n",
      "                \"project_id\": \"gurkomal-playground\",\n",
      "                \"machine_type\": \"n1-standard-2\",\n",
      "                \"location\": \"us-central1\",\n",
      "                \"endpoint_name\": \"test\",\n",
      "                \"should_deploy\": false\n",
      "            }\n",
      "        },\n",
      "        \"outputs\": {\n",
      "            \"outputFile\": \"/home/jupyter/local_outputs/deploy-model-2024-08-15-23-23-26-859151/deploy-model/executor_output.json\"\n",
      "        }\n",
      "    }\n",
      "    [KFP Executor 2024-08-15 23:23:50,410 INFO]: Numpy was not imported, continuing without requires()\n",
      "    Model deployment skipped as per comparison result.\n",
      "    [KFP Executor 2024-08-15 23:23:50,622 INFO]: Wrote executor output file to /home/jupyter/local_outputs/deploy-model-2024-08-15-23-23-26-859151/deploy-model/executor_output.json.\n",
      "    /usr/local/lib/python3.7/runpy.py:109: FutureWarning: Python 3.7 has reached end-of-life. KFP will drop support for Python 3.7 on April 23, 2024. To use new versions of the KFP SDK after that date, you will need to upgrade to Python >= 3.8. See https://devguide.python.org/versions/ for more details.\n",
      "      __import__(pkg_name)\n",
      "23:23:52.015 - INFO - Task \u001b[96m'deploy-model'\u001b[0m finished with status \u001b[92mSUCCESS\u001b[0m\n",
      "23:23:52.017 - INFO - Task \u001b[96m'deploy-model'\u001b[0m has no outputs\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<kfp.dsl.pipeline_task.PipelineTask at 0x7efef1bc2e30>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Deploy model\n",
    "deploy_model(project_id=config['project_id'],location=config['location'], \n",
    "             model_name=config['model_name'], endpoint_name=config['endpoint_name'],\n",
    "             should_deploy=should_deploy.output,\n",
    "            machine_type=config['machine_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8e22d2b1-b101-4178-b0c7-82648b3121b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7d16f9abda442a8d73d0dd2270ac6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Query is running:   0%|          |"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641c859-8ecd-4db4-8688-ae6990a57f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "CREATE TABLE avoxi_workshop.detected_anomalies AS(\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.DETECT_ANOMALIES(MODEL `avoxi_workshop.anomaly_autoencoder_v3`,\n",
    "    STRUCT(0.03 AS contamination),\n",
    "    TABLE `avoxi_workshop.eval_set`))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f338a2-e0b3-40a2-9571-61ed66b27a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m123",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m123"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
