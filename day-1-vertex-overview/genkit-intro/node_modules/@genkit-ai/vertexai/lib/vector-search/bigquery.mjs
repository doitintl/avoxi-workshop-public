import {
  __async
} from "../chunk-WFI2LP4G.mjs";
import { Document, DocumentDataSchema } from "@genkit-ai/ai/retriever";
import { logger } from "@genkit-ai/core/logging";
import { ZodError } from "zod";
const getBigQueryDocumentRetriever = (bq, tableId, datasetId) => {
  const bigQueryRetriever = (neighbors) => __async(void 0, null, function* () {
    const ids = neighbors.map((neighbor) => {
      var _a;
      return (_a = neighbor.datapoint) == null ? void 0 : _a.datapointId;
    }).filter(Boolean);
    const query = `
      SELECT * FROM \`${datasetId}.${tableId}\`
      WHERE id IN UNNEST(@ids)
    `;
    const options = {
      query,
      params: { ids }
    };
    let rows;
    try {
      [rows] = yield bq.query(options);
    } catch (queryError) {
      logger.error("Failed to execute BigQuery query:", queryError);
      return [];
    }
    const documents = [];
    for (const row of rows) {
      try {
        const docData = {
          content: JSON.parse(row.content)
        };
        if (row.metadata) {
          docData.metadata = JSON.parse(row.metadata);
        }
        const parsedDocData = DocumentDataSchema.parse(docData);
        documents.push(new Document(parsedDocData));
      } catch (error) {
        const id = row.id;
        const errorPrefix = `Failed to parse document data for document with ID ${id}:`;
        if (error instanceof ZodError || error instanceof Error) {
          logger.warn(`${errorPrefix} ${error.message}`);
        } else {
          logger.warn(errorPrefix);
        }
      }
    }
    return documents;
  });
  return bigQueryRetriever;
};
const getBigQueryDocumentIndexer = (bq, tableId, datasetId) => {
  const bigQueryIndexer = (docs) => __async(void 0, null, function* () {
    const ids = [];
    const rows = docs.map((doc) => {
      const id = Math.random().toString(36).substring(7);
      ids.push(id);
      return {
        id,
        content: JSON.stringify(doc.content),
        metadata: JSON.stringify(doc.metadata)
      };
    });
    yield bq.dataset(datasetId).table(tableId).insert(rows);
    return ids;
  });
  return bigQueryIndexer;
};
export {
  getBigQueryDocumentIndexer,
  getBigQueryDocumentRetriever
};
//# sourceMappingURL=bigquery.mjs.map