"use strict";
var __defProp = Object.defineProperty;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};
var bigquery_exports = {};
__export(bigquery_exports, {
  getBigQueryDocumentIndexer: () => getBigQueryDocumentIndexer,
  getBigQueryDocumentRetriever: () => getBigQueryDocumentRetriever
});
module.exports = __toCommonJS(bigquery_exports);
var import_retriever = require("@genkit-ai/ai/retriever");
var import_logging = require("@genkit-ai/core/logging");
var import_zod = require("zod");
const getBigQueryDocumentRetriever = (bq, tableId, datasetId) => {
  const bigQueryRetriever = (neighbors) => __async(void 0, null, function* () {
    const ids = neighbors.map((neighbor) => {
      var _a;
      return (_a = neighbor.datapoint) == null ? void 0 : _a.datapointId;
    }).filter(Boolean);
    const query = `
      SELECT * FROM \`${datasetId}.${tableId}\`
      WHERE id IN UNNEST(@ids)
    `;
    const options = {
      query,
      params: { ids }
    };
    let rows;
    try {
      [rows] = yield bq.query(options);
    } catch (queryError) {
      import_logging.logger.error("Failed to execute BigQuery query:", queryError);
      return [];
    }
    const documents = [];
    for (const row of rows) {
      try {
        const docData = {
          content: JSON.parse(row.content)
        };
        if (row.metadata) {
          docData.metadata = JSON.parse(row.metadata);
        }
        const parsedDocData = import_retriever.DocumentDataSchema.parse(docData);
        documents.push(new import_retriever.Document(parsedDocData));
      } catch (error) {
        const id = row.id;
        const errorPrefix = `Failed to parse document data for document with ID ${id}:`;
        if (error instanceof import_zod.ZodError || error instanceof Error) {
          import_logging.logger.warn(`${errorPrefix} ${error.message}`);
        } else {
          import_logging.logger.warn(errorPrefix);
        }
      }
    }
    return documents;
  });
  return bigQueryRetriever;
};
const getBigQueryDocumentIndexer = (bq, tableId, datasetId) => {
  const bigQueryIndexer = (docs) => __async(void 0, null, function* () {
    const ids = [];
    const rows = docs.map((doc) => {
      const id = Math.random().toString(36).substring(7);
      ids.push(id);
      return {
        id,
        content: JSON.stringify(doc.content),
        metadata: JSON.stringify(doc.metadata)
      };
    });
    yield bq.dataset(datasetId).table(tableId).insert(rows);
    return ids;
  });
  return bigQueryIndexer;
};
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  getBigQueryDocumentIndexer,
  getBigQueryDocumentRetriever
});
//# sourceMappingURL=bigquery.js.map