"use strict";
var __defProp = Object.defineProperty;
var __defProps = Object.defineProperties;
var __getOwnPropDesc = Object.getOwnPropertyDescriptor;
var __getOwnPropDescs = Object.getOwnPropertyDescriptors;
var __getOwnPropNames = Object.getOwnPropertyNames;
var __getOwnPropSymbols = Object.getOwnPropertySymbols;
var __hasOwnProp = Object.prototype.hasOwnProperty;
var __propIsEnum = Object.prototype.propertyIsEnumerable;
var __defNormalProp = (obj, key, value) => key in obj ? __defProp(obj, key, { enumerable: true, configurable: true, writable: true, value }) : obj[key] = value;
var __spreadValues = (a, b) => {
  for (var prop in b || (b = {}))
    if (__hasOwnProp.call(b, prop))
      __defNormalProp(a, prop, b[prop]);
  if (__getOwnPropSymbols)
    for (var prop of __getOwnPropSymbols(b)) {
      if (__propIsEnum.call(b, prop))
        __defNormalProp(a, prop, b[prop]);
    }
  return a;
};
var __spreadProps = (a, b) => __defProps(a, __getOwnPropDescs(b));
var __export = (target, all) => {
  for (var name in all)
    __defProp(target, name, { get: all[name], enumerable: true });
};
var __copyProps = (to, from, except, desc) => {
  if (from && typeof from === "object" || typeof from === "function") {
    for (let key of __getOwnPropNames(from))
      if (!__hasOwnProp.call(to, key) && key !== except)
        __defProp(to, key, { get: () => from[key], enumerable: !(desc = __getOwnPropDesc(from, key)) || desc.enumerable });
  }
  return to;
};
var __toCommonJS = (mod) => __copyProps(__defProp({}, "__esModule", { value: true }), mod);
var __async = (__this, __arguments, generator) => {
  return new Promise((resolve, reject) => {
    var fulfilled = (value) => {
      try {
        step(generator.next(value));
      } catch (e) {
        reject(e);
      }
    };
    var rejected = (value) => {
      try {
        step(generator.throw(value));
      } catch (e) {
        reject(e);
      }
    };
    var step = (x) => x.done ? resolve(x.value) : Promise.resolve(x.value).then(fulfilled, rejected);
    step((generator = generator.apply(__this, __arguments)).next());
  });
};
var embedder_exports = {};
__export(embedder_exports, {
  SUPPORTED_EMBEDDER_MODELS: () => SUPPORTED_EMBEDDER_MODELS,
  TaskTypeSchema: () => TaskTypeSchema,
  TextEmbeddingGeckoConfigSchema: () => TextEmbeddingGeckoConfigSchema,
  textEmbedding004: () => textEmbedding004,
  textEmbeddingGecko: () => textEmbeddingGecko,
  textEmbeddingGecko001: () => textEmbeddingGecko001,
  textEmbeddingGecko002: () => textEmbeddingGecko002,
  textEmbeddingGecko003: () => textEmbeddingGecko003,
  textEmbeddingGeckoEmbedder: () => textEmbeddingGeckoEmbedder,
  textEmbeddingGeckoMultilingual001: () => textEmbeddingGeckoMultilingual001,
  textMultilingualEmbedding002: () => textMultilingualEmbedding002
});
module.exports = __toCommonJS(embedder_exports);
var import_embedder = require("@genkit-ai/ai/embedder");
var import_zod = require("zod");
var import_predict = require("./predict.js");
const TaskTypeSchema = import_zod.z.enum([
  "RETRIEVAL_DOCUMENT",
  "RETRIEVAL_QUERY",
  "SEMANTIC_SIMILARITY",
  "CLASSIFICATION",
  "CLUSTERING"
]);
const TextEmbeddingGeckoConfigSchema = import_zod.z.object({
  /**
   * The `task_type` parameter is defined as the intended downstream application to help the model
   * produce better quality embeddings.
   **/
  taskType: TaskTypeSchema.optional(),
  title: import_zod.z.string().optional(),
  location: import_zod.z.string().optional()
});
const textEmbeddingGecko003 = (0, import_embedder.embedderRef)({
  name: "vertexai/textembedding-gecko@003",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko002 = (0, import_embedder.embedderRef)({
  name: "vertexai/textembedding-gecko@002",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko001 = (0, import_embedder.embedderRef)({
  name: "vertexai/textembedding-gecko@001",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding Gecko (Legacy)",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbedding004 = (0, import_embedder.embedderRef)({
  name: "vertexai/text-embedding-004",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Embedding 004",
    supports: {
      input: ["text"]
    }
  }
});
const textMultilingualEmbedding002 = (0, import_embedder.embedderRef)({
  name: "vertexai/text-multilingual-embedding-002",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Text Multilingual Embedding 002",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGeckoMultilingual001 = (0, import_embedder.embedderRef)({
  name: "vertexai/textembedding-gecko-multilingual@001",
  configSchema: TextEmbeddingGeckoConfigSchema,
  info: {
    dimensions: 768,
    label: "Vertex AI - Multilingual Text Embedding Gecko 001",
    supports: {
      input: ["text"]
    }
  }
});
const textEmbeddingGecko = textEmbeddingGecko003;
const SUPPORTED_EMBEDDER_MODELS = {
  "textembedding-gecko@003": textEmbeddingGecko003,
  "textembedding-gecko@002": textEmbeddingGecko002,
  "textembedding-gecko@001": textEmbeddingGecko001,
  "text-embedding-004": textEmbedding004,
  "textembedding-gecko-multilingual@001": textEmbeddingGeckoMultilingual001,
  "text-multilingual-embedding-002": textMultilingualEmbedding002
};
function textEmbeddingGeckoEmbedder(name, client, options) {
  const embedder = SUPPORTED_EMBEDDER_MODELS[name];
  const predictClients = {};
  const predictClientFactory = (config) => {
    const requestLocation = (config == null ? void 0 : config.location) || options.location;
    if (!predictClients[requestLocation]) {
      predictClients[requestLocation] = (0, import_predict.predictModel)(
        client,
        __spreadProps(__spreadValues({}, options), {
          location: requestLocation
        }),
        name
      );
    }
    return predictClients[requestLocation];
  };
  return (0, import_embedder.defineEmbedder)(
    {
      name: embedder.name,
      configSchema: embedder.configSchema,
      info: embedder.info
    },
    (input, options2) => __async(this, null, function* () {
      const predictClient = predictClientFactory(options2);
      const response = yield predictClient(
        input.map((i) => {
          return {
            content: i.text(),
            task_type: options2 == null ? void 0 : options2.taskType,
            title: options2 == null ? void 0 : options2.title
          };
        })
      );
      return {
        embeddings: response.predictions.map((p) => ({
          embedding: p.embeddings.values
        }))
      };
    })
  );
}
// Annotate the CommonJS export names for ESM import in node:
0 && (module.exports = {
  SUPPORTED_EMBEDDER_MODELS,
  TaskTypeSchema,
  TextEmbeddingGeckoConfigSchema,
  textEmbedding004,
  textEmbeddingGecko,
  textEmbeddingGecko001,
  textEmbeddingGecko002,
  textEmbeddingGecko003,
  textEmbeddingGeckoEmbedder,
  textEmbeddingGeckoMultilingual001,
  textMultilingualEmbedding002
});
//# sourceMappingURL=embedder.js.map